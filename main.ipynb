{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, dev, test = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in open('./train_enc.tsv', encoding='utf-8'):\n",
        "    x = x.rstrip('\\n\\r').split('\\t')\n",
        "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
        "    x[0] = int(x[0]) \n",
        "    train.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in open('./dev_enc.tsv', encoding='utf-8'):\n",
        "    x = x.rstrip('\\n\\r').split('\\t')\n",
        "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
        "    x[0] = int(x[0]) \n",
        "    dev.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in open('./test_enc_unlabeled.tsv', encoding='utf-8'):\n",
        "    x = x.rstrip('\\n\\r')\n",
        "    test.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_split = [[x[0], x[1].split(' ')] for x in train]\n",
        "dev_split = [[x[0], x[1].split(' ')] for x in dev]\n",
        "test_split = [[x.split(' ')] for x in test]\n",
        "\n",
        "X_train = [x[1] for x in train_split]\n",
        "\n",
        "from collections import defaultdict\n",
        "vocab = defaultdict(lambda : 999999)\n",
        "\n",
        "count = 3\n",
        "for sent in X_train:\n",
        "    for word in sent:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = count\n",
        "            count+=1\n",
        "\n",
        "def prep(lister):\n",
        "    for i, sent in enumerate(lister):\n",
        "        for j, word in enumerate(sent):\n",
        "            try:\n",
        "                lister[i][j] = vocab[word]\n",
        "            except:\n",
        "                print(i, lister[i])\n",
        "\n",
        "for i, sent in enumerate(X_train):\n",
        "    for j, word in enumerate(sent):\n",
        "        X_train[i][j] = vocab[word]\n",
        "\n",
        "y_train = [x[0] for x in train_split]\n",
        "\n",
        "\n",
        "\n",
        "X_val = [x[1] for x in dev_split]\n",
        "\n",
        "for i, sent in enumerate(X_val):\n",
        "    for j, word in enumerate(sent):\n",
        "        X_val[i][j] = vocab[word]\n",
        "\n",
        "y_val = [x[0] for x in dev_split]\n",
        "\n",
        "\n",
        "X_test = [x[0] for x in test_split]\n",
        "for i, sent in enumerate(X_test):\n",
        "    for j, word in enumerate(sent):\n",
        "        X_test[i][j] = vocab[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_train = np.array([np.array(x) for x in X_train])\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array([np.array(x) for x in X_val])\n",
        "y_cv = np.array(y_val)\n",
        "X_test = np.array([np.array(x) for x in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense,Conv1D,MaxPooling1D,LSTM,Dropout,GRU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "np.random.seed(42)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape -  (16220, 300)\n",
            "Test data shape -  (2028, 300)\n",
            "Val data shape -  (2027, 300)\n"
          ]
        }
      ],
      "source": [
        "print('Train data shape - ', X_train.shape)\n",
        "print('Test data shape - ', X_test.shape)\n",
        "print('Val data shape - ', X_val.shape)\n",
        "\n",
        "MAX_SENT_LEN = 300\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_SENT_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SENT_LEN)\n",
        "X_val = sequence.pad_sequences(X_val,maxlen=MAX_SENT_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMBEDDING_SIZE = 64\n",
        "TOP_WORDS = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, 300, 64)           640000    \n",
            "                                                                 \n",
            " gru_18 (GRU)                (None, 300, 64)           24960     \n",
            "                                                                 \n",
            " gru_19 (GRU)                (None, 300, 128)          74496     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 300, 128)          0         \n",
            "                                                                 \n",
            " gru_20 (GRU)                (None, 300, 256)          296448    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 300, 256)          0         \n",
            "                                                                 \n",
            " gru_21 (GRU)                (None, 300, 128)          148224    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 300, 128)          0         \n",
            "                                                                 \n",
            " gru_22 (GRU)                (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,221,441\n",
            "Trainable params: 1,221,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.7025\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81105, saving model to .\\weights_best_own.hdf5\n",
            "127/127 [==============================] - 14s 79ms/step - loss: 0.5459 - accuracy: 0.7025 - val_loss: 0.4265 - val_accuracy: 0.8111\n",
            "Epoch 2/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8724\n",
            "Epoch 2: val_accuracy improved from 0.81105 to 0.84706, saving model to .\\weights_best_own.hdf5\n",
            "127/127 [==============================] - 9s 72ms/step - loss: 0.3077 - accuracy: 0.8724 - val_loss: 0.3777 - val_accuracy: 0.8471\n",
            "Epoch 3/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9191\n",
            "Epoch 3: val_accuracy improved from 0.84706 to 0.85841, saving model to .\\weights_best_own.hdf5\n",
            "127/127 [==============================] - 9s 72ms/step - loss: 0.2172 - accuracy: 0.9191 - val_loss: 0.3968 - val_accuracy: 0.8584\n",
            "Epoch 4/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9424\n",
            "Epoch 4: val_accuracy improved from 0.85841 to 0.86236, saving model to .\\weights_best_own.hdf5\n",
            "127/127 [==============================] - 9s 72ms/step - loss: 0.1620 - accuracy: 0.9424 - val_loss: 0.4027 - val_accuracy: 0.8624\n",
            "Epoch 5/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9559\n",
            "Epoch 5: val_accuracy improved from 0.86236 to 0.87568, saving model to .\\weights_best_own.hdf5\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.1315 - accuracy: 0.9559 - val_loss: 0.3864 - val_accuracy: 0.8757\n",
            "Epoch 6/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9669\n",
            "Epoch 6: val_accuracy did not improve from 0.87568\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.1061 - accuracy: 0.9669 - val_loss: 0.4129 - val_accuracy: 0.8747\n",
            "Epoch 7/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9674\n",
            "Epoch 7: val_accuracy improved from 0.87568 to 0.88259, saving model to .\\weights_best_own.hdf5\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0986 - accuracy: 0.9674 - val_loss: 0.3961 - val_accuracy: 0.8826\n",
            "Epoch 8/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9707\n",
            "Epoch 8: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0862 - accuracy: 0.9707 - val_loss: 0.5024 - val_accuracy: 0.8772\n",
            "Epoch 9/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9744\n",
            "Epoch 9: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0735 - accuracy: 0.9744 - val_loss: 0.4771 - val_accuracy: 0.8767\n",
            "Epoch 10/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9757\n",
            "Epoch 10: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0682 - accuracy: 0.9757 - val_loss: 0.4423 - val_accuracy: 0.8767\n",
            "Epoch 11/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9774\n",
            "Epoch 11: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0607 - accuracy: 0.9774 - val_loss: 0.4853 - val_accuracy: 0.8752\n",
            "Epoch 12/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9782\n",
            "Epoch 12: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0540 - accuracy: 0.9782 - val_loss: 0.5676 - val_accuracy: 0.8732\n",
            "Epoch 13/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9790\n",
            "Epoch 13: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0479 - accuracy: 0.9790 - val_loss: 0.5329 - val_accuracy: 0.8742\n",
            "Epoch 14/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9811\n",
            "Epoch 14: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0408 - accuracy: 0.9811 - val_loss: 0.6268 - val_accuracy: 0.8712\n",
            "Epoch 15/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9820\n",
            "Epoch 15: val_accuracy did not improve from 0.88259\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.0401 - accuracy: 0.9820 - val_loss: 0.6843 - val_accuracy: 0.8624\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2589ab78b50>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(TOP_WORDS, EMBEDDING_SIZE, input_length=MAX_SENT_LEN))\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(GRU(128, return_sequences=True))\n",
        "model.add(Dropout(0.01))\n",
        "model.add(GRU(256, return_sequences=True))\n",
        "model.add(Dropout(0.01))\n",
        "model.add(GRU(128, return_sequences=True))\n",
        "model.add(Dropout(0.02))\n",
        "model.add(GRU(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "filepath=\"./weights_best_own.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=128, verbose = 1,callbacks = callbacks_list,validation_data=(X_val,y_cv))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "8/8 [==============================] - 4s 444ms/step - loss: 0.4092 - accuracy: 0.8648\n",
            "Accuracy: 86.48%\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(TOP_WORDS, EMBEDDING_SIZE, input_length=MAX_SENT_LEN))\n",
        "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.1))\n",
        "# model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.load_weights(\"weights_best_own.hdf5\")\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "scores = model.evaluate(X_val, y_cv, verbose=1,batch_size = 256)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_23 (Embedding)    (None, 300, 64)           640000    \n",
            "                                                                 \n",
            " conv1d_55 (Conv1D)          (None, 300, 64)           12352     \n",
            "                                                                 \n",
            " conv1d_56 (Conv1D)          (None, 300, 64)           12352     \n",
            "                                                                 \n",
            " conv1d_57 (Conv1D)          (None, 300, 128)          24704     \n",
            "                                                                 \n",
            " conv1d_58 (Conv1D)          (None, 300, 256)          98560     \n",
            "                                                                 \n",
            " conv1d_59 (Conv1D)          (None, 300, 128)          98432     \n",
            "                                                                 \n",
            " conv1d_60 (Conv1D)          (None, 300, 64)           24640     \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 150, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 256)               328704    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,240,001\n",
            "Trainable params: 1,240,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.5427\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75234, saving model to weights_best_cnn_own.hdf5\n",
            "127/127 [==============================] - 7s 42ms/step - loss: 0.6773 - accuracy: 0.5427 - val_loss: 0.5139 - val_accuracy: 0.7523\n",
            "Epoch 2/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8313\n",
            "Epoch 2: val_accuracy improved from 0.75234 to 0.85200, saving model to weights_best_cnn_own.hdf5\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.3946 - accuracy: 0.8313 - val_loss: 0.3700 - val_accuracy: 0.8520\n",
            "Epoch 3/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9138\n",
            "Epoch 3: val_accuracy improved from 0.85200 to 0.86334, saving model to weights_best_cnn_own.hdf5\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.2293 - accuracy: 0.9138 - val_loss: 0.3511 - val_accuracy: 0.8633\n",
            "Epoch 4/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.9446\n",
            "Epoch 4: val_accuracy improved from 0.86334 to 0.86581, saving model to weights_best_cnn_own.hdf5\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.1574 - accuracy: 0.9446 - val_loss: 0.4068 - val_accuracy: 0.8658\n",
            "Epoch 5/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9596\n",
            "Epoch 5: val_accuracy improved from 0.86581 to 0.87617, saving model to weights_best_cnn_own.hdf5\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.1161 - accuracy: 0.9596 - val_loss: 0.4033 - val_accuracy: 0.8762\n",
            "Epoch 6/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9682\n",
            "Epoch 6: val_accuracy did not improve from 0.87617\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0905 - accuracy: 0.9682 - val_loss: 0.4300 - val_accuracy: 0.8747\n",
            "Epoch 7/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9729\n",
            "Epoch 7: val_accuracy improved from 0.87617 to 0.88012, saving model to weights_best_cnn_own.hdf5\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0735 - accuracy: 0.9729 - val_loss: 0.4688 - val_accuracy: 0.8801\n",
            "Epoch 8/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9780\n",
            "Epoch 8: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0595 - accuracy: 0.9780 - val_loss: 0.4762 - val_accuracy: 0.8791\n",
            "Epoch 9/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9805\n",
            "Epoch 9: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0508 - accuracy: 0.9805 - val_loss: 0.4952 - val_accuracy: 0.8781\n",
            "Epoch 10/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9817\n",
            "Epoch 10: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0448 - accuracy: 0.9817 - val_loss: 0.5529 - val_accuracy: 0.8742\n",
            "Epoch 11/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9845\n",
            "Epoch 11: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0369 - accuracy: 0.9845 - val_loss: 0.5942 - val_accuracy: 0.8707\n",
            "Epoch 12/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9825\n",
            "Epoch 12: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0389 - accuracy: 0.9825 - val_loss: 0.6023 - val_accuracy: 0.8796\n",
            "Epoch 13/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9851\n",
            "Epoch 13: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0320 - accuracy: 0.9851 - val_loss: 0.6465 - val_accuracy: 0.8752\n",
            "Epoch 14/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9850\n",
            "Epoch 14: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0307 - accuracy: 0.9850 - val_loss: 0.6807 - val_accuracy: 0.8683\n",
            "Epoch 15/15\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9858\n",
            "Epoch 15: val_accuracy did not improve from 0.88012\n",
            "127/127 [==============================] - 5s 40ms/step - loss: 0.0274 - accuracy: 0.9858 - val_loss: 0.6717 - val_accuracy: 0.8767\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x258abf88fd0>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(TOP_WORDS, EMBEDDING_SIZE, input_length=MAX_SENT_LEN))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "filepath=\"weights_best_cnn_own.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=128,verbose = 1,callbacks = callbacks_list,validation_data=(X_val,y_cv))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 600, 64)           640000    \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 600, 64)           12352     \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 600, 128)          24704     \n",
            "                                                                 \n",
            " conv1d_22 (Conv1D)          (None, 600, 256)          98560     \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 600, 128)          98432     \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 600, 64)           24640     \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 200, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 256)               247296    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,146,241\n",
            "Trainable params: 1,146,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 88.7518525%\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(TOP_WORDS, EMBEDDING_SIZE, input_length=MAX_SENT_LEN))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(GRU(256))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.load_weights(\"weights_best_cnn_own.hdf5\")\n",
        "scores = model.evaluate(X_val, y_cv, verbose=0)\n",
        "print(\"Accuracy: %.7f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00049794]\n"
          ]
        }
      ],
      "source": [
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_pred = [1 if x>=0.5 else 0 for x in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0, 1}\n"
          ]
        }
      ],
      "source": [
        "print(set(new_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 1028, 1: 1000})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print(Counter(new_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('upload_predictions.txt', 'w', encoding = 'utf-8') as fp:\n",
        "    for x in new_pred:\n",
        "        fp.write(str(x) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88.75185251235962\n"
          ]
        }
      ],
      "source": [
        "print(scores[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f'upload_predictions_{scores[1]*100}.txt', 'w', encoding = 'utf-8') as fp:\n",
        "    for x in new_pred:\n",
        "        fp.write(str(x) + '\\n')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
